{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import pipeline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T05:40:25.880574Z","iopub.execute_input":"2024-12-01T05:40:25.881272Z","iopub.status.idle":"2024-12-01T05:40:25.885448Z","shell.execute_reply.started":"2024-12-01T05:40:25.881227Z","shell.execute_reply":"2024-12-01T05:40:25.884360Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"cls = pipeline(\"sentiment-analysis\")\ncls(\"i love you\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T05:40:27.270357Z","iopub.execute_input":"2024-12-01T05:40:27.270679Z","iopub.status.idle":"2024-12-01T05:40:27.796580Z","shell.execute_reply.started":"2024-12-01T05:40:27.270653Z","shell.execute_reply":"2024-12-01T05:40:27.795612Z"}},"outputs":[{"name":"stderr","text":"No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\nHardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"[{'label': 'POSITIVE', 'score': 0.9998656511306763}]"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"zsc = pipeline(\"zero-shot-classification\")\n\nzsc(    \"This is a course about the Transformers library\",\n   candidate_labels=[\"education\" ,  \"politics\", \"business\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T05:40:32.479041Z","iopub.execute_input":"2024-12-01T05:40:32.479387Z","iopub.status.idle":"2024-12-01T05:40:34.723712Z","shell.execute_reply.started":"2024-12-01T05:40:32.479361Z","shell.execute_reply":"2024-12-01T05:40:34.722809Z"}},"outputs":[{"name":"stderr","text":"No model was supplied, defaulted to facebook/bart-large-mnli and revision d7645e1 (https://huggingface.co/facebook/bart-large-mnli).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\nHardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"{'sequence': 'This is a course about the Transformers library',\n 'labels': ['education', 'business', 'politics'],\n 'scores': [0.8445969223976135, 0.11197589337825775, 0.04342729598283768]}"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"gen =  pipeline(\"text-generation\", model=\"distilgpt2\")\ngen(\n\"in this course we will teach you\",\nmax_length =30,\nnum_return_sequences=3\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T05:40:34.856751Z","iopub.execute_input":"2024-12-01T05:40:34.857070Z","iopub.status.idle":"2024-12-01T05:40:36.111732Z","shell.execute_reply.started":"2024-12-01T05:40:34.857043Z","shell.execute_reply":"2024-12-01T05:40:36.110729Z"}},"outputs":[{"name":"stderr","text":"Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\nTruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"[{'generated_text': 'in this course we will teach you about the art and the art of dancing, music and more. This course will require you to be able to dance'},\n {'generated_text': 'in this course we will teach you basic English.â€¹'},\n {'generated_text': 'in this course we will teach you in some way about these topics so we are more flexible, more concise, more enjoyable, and, in general,'}]"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"ner = pipeline(\"ner\" , grouped_entities=True)\nner(\"my name is sayed ali and i am AI eng \")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T05:40:36.113578Z","iopub.execute_input":"2024-12-01T05:40:36.113932Z","iopub.status.idle":"2024-12-01T05:40:36.653718Z","shell.execute_reply.started":"2024-12-01T05:40:36.113900Z","shell.execute_reply":"2024-12-01T05:40:36.652794Z"}},"outputs":[{"name":"stderr","text":"No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\nSome weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nHardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"[{'entity_group': 'PER',\n  'score': 0.7700708,\n  'word': 'say',\n  'start': 11,\n  'end': 14},\n {'entity_group': 'PER',\n  'score': 0.5840235,\n  'word': 'al',\n  'start': 17,\n  'end': 19}]"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"qa = pipeline(\"question-answering\")\n\nqa(question=\"What is the AI\" , \n  context=\"AI IS Big Data and Trend of The World .\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T05:40:36.654892Z","iopub.execute_input":"2024-12-01T05:40:36.655234Z","iopub.status.idle":"2024-12-01T05:40:36.851135Z","shell.execute_reply.started":"2024-12-01T05:40:36.655204Z","shell.execute_reply":"2024-12-01T05:40:36.850242Z"}},"outputs":[{"name":"stderr","text":"No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\nHardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"{'score': 0.3460571765899658,\n 'start': 3,\n 'end': 37,\n 'answer': 'IS Big Data and Trend of The World'}"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"sum = pipeline(\"summarization\")\n\nsum( \"\"\"\n    America has changed dramatically during recent years. Not only has the number of \n    graduates in traditional engineering disciplines such as mechanical, civil, \n    electrical, chemical, and aeronautical engineering declined, but in most of \n    the premier American universities engineering curricula now concentrate on \n    and encourage largely the study of engineering science. As a result, there \n    are declining offerings in engineering subjects dealing with infrastructure, \n    the environment, and related issues, and greater concentration on high \n    technology subjects, largely supporting increasingly complex scientific \n    developments. While the latter is important, it should not be at the expense \n    of more traditional engineering.\"\"\")\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T05:40:36.852888Z","iopub.execute_input":"2024-12-01T05:40:36.853205Z","iopub.status.idle":"2024-12-01T05:40:42.339094Z","shell.execute_reply.started":"2024-12-01T05:40:36.853174Z","shell.execute_reply":"2024-12-01T05:40:42.338146Z"}},"outputs":[{"name":"stderr","text":"No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\nHardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"[{'summary_text': ' America has changed dramatically during recent years . The number of engineering graduates in America has declined in traditional engineering disciplines such as mechanical, civil,    electrical, chemical, and aeronautical engineering . Engineering curricula now concentrate on  the study of engineering science rather than engineering science .'}]"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"tran = pipeline(\"translation\" , model=\"Helsinki-NLP/opus-mt-ar-en\")\n\ntran(\"Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ… \")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T05:40:42.340242Z","iopub.execute_input":"2024-12-01T05:40:42.340544Z","iopub.status.idle":"2024-12-01T05:40:44.528715Z","shell.execute_reply.started":"2024-12-01T05:40:42.340513Z","shell.execute_reply":"2024-12-01T05:40:44.527815Z"}},"outputs":[{"name":"stderr","text":"Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"[{'translation_text': 'Peace be upon you.'}]"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}